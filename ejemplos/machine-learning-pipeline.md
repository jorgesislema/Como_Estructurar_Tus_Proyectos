
# Ejemplo: Pipeline de Machine Learning Reproducible (DVC, Scikit-learn)

Â¡Hola, cientÃ­ficos de datos y entusiastas de MLOps! Este repositorio es una plantilla de ejemplo para estructurar un proyecto de Machine Learning enfocado en la **reproducibilidad, versionado y automatizaciÃ³n** usando **DVC (Data Version Control)**.

En el mundo del ML, no basta con tener buen cÃ³digo; necesitamos versionar los datos con los que entrenamos, los modelos que producimos, los parÃ¡metros que usamos y las mÃ©tricas que obtenemos. DVC, junto con Git, nos permite hacer exactamente eso, ademÃ¡s de definir y ejecutar pipelines de forma eficiente. Este ejemplo usa **Scikit-learn** para las tareas de ML, pero la estructura es adaptable a otros frameworks como PyTorch o TensorFlow.

## Objetivo ğŸ¯

* Proveer una **estructura estÃ¡ndar y lÃ³gica** para proyectos de ML basada en MLOps.
* Demostrar cÃ³mo usar **DVC** para:
    * **Versionar datos y modelos** grandes sin sobrecargar Git.
    * Definir y ejecutar un **pipeline de ML reproducible** (`dvc.yaml`).
    * Gestionar **parÃ¡metros** (`params.yaml`) y **mÃ©tricas** (`metrics.json`).
* Fomentar el **cÃ³digo modular** para cada etapa del pipeline (`src/`).
* Servir como un **punto de partida prÃ¡ctico** que puedes clonar y adaptar.

## TecnologÃ­as Clave ğŸ› ï¸

* **OrquestaciÃ³n / Versionado Datos/Modelos:** [DVC (Data Version Control)](https://dvc.org/)
* **Control de Versiones CÃ³digo/Params:** [Git](https://git-scm.com/)
* **ML Framework (Ejemplo):** [Scikit-learn](https://scikit-learn.org/)
* **ManipulaciÃ³n de Datos:** [Pandas](https://pandas.pydata.org/), [NumPy](https://numpy.org/)
* **GestiÃ³n de Dependencias:** [Poetry](https://python-poetry.org/) o [Hatch](https://hatch.pypa.io/) (vÃ­a `pyproject.toml`)
* **ConfiguraciÃ³n/ParÃ¡metros:** Archivos YAML (`params.yaml`)
* **Testing:** [Pytest](https://pytest.org/)
* **(Opcional) Seguimiento de Experimentos:** [MLflow](https://mlflow.org/) (se puede integrar en los scripts de `src/`)

## Estructura del Directorio ğŸ—ºï¸

Esta estructura separa claramente el cÃ³digo, los datos, los modelos, la configuraciÃ³n y los resultados:

* **`data/`**: Contiene los datos en diferentes estados (raw, processed, etc.). **Importante:** Los archivos grandes aquÃ­ no estÃ¡n en Git directamente, sino que son gestionados por DVC (verÃ¡s archivos `.dvc` que son pequeÃ±os punteros de metadatos versionados por Git).
* **`models/`**: Similar a `data/`, almacena los modelos entrenados serializados, gestionados por DVC.
* **`src/ml_pipeline/`**: CÃ³digo fuente Python modularizado. Cada script principal aquÃ­ (`make_dataset.py`, `train_model.py`, etc.) corresponde idealmente a una etapa definida en `dvc.yaml`.
* **`notebooks/`**: Para exploraciÃ³n y anÃ¡lisis inicial. Â¡Evita poner lÃ³gica crÃ­tica de producciÃ³n aquÃ­! Transfiere el cÃ³digo Ãºtil a `src/`.
* **`tests/`**: Pruebas unitarias y de integraciÃ³n para el cÃ³digo en `src/`.
* **`dvc.yaml`**: **Archivo Central del Pipeline.** Define las etapas (stages) del flujo de trabajo (ej: `process_data`, `train`, `evaluate`). Cada etapa especifica:
    * `cmd`: El comando a ejecutar (ej: `python src/ml_pipeline/models/train_model.py`).
    * `deps`: Dependencias (scripts, datos de entrada).
    * `outs`: Salidas (datos procesados, modelos). DVC las cachea.
    * `params`: ParÃ¡metros de `params.yaml` que afectan esta etapa.
    * `metrics`: Archivos de mÃ©tricas generados (ej: `metrics.json`).
* **`params.yaml`**: Archivo simple para definir parÃ¡metros (hiperparÃ¡metros del modelo, umbrales, nombres de caracterÃ­sticas) que quieres versionar con Git y pasar a tus scripts. DVC rastrea cambios aquÃ­.
* **`metrics.json`, `plots.json`**: Archivos generados por DVC que contienen las mÃ©tricas y datos para visualizaciones, permitiendo comparar experimentos (`dvc metrics diff`, `dvc plots diff`).
* **`pyproject.toml`**: Define las dependencias Python del proyecto y configuraciÃ³n de herramientas.
* **`.dvc/`**: Directorio interno de DVC. No necesitas tocarlo usualmente, pero contiene la configuraciÃ³n local y punteros al cache.
* **`.dvcignore`**: Similar a `.gitignore`, pero le dice a DVC quÃ© archivos ignorar al buscar dependencias o salidas.

## CÃ³mo Usar esta Plantilla ğŸš€

1.  **Prerrequisitos:**
    * Python (3.8+)
    * Git
    * DVC: `pip install dvc` (o `pip install dvc[s3,gcs,azure,ssh]` para incluir soporte de almacenamiento remoto).
    * (Opcional) Un gestor de paquetes como Poetry (`pip install poetry`) o Hatch (`pip install hatch`).
2.  **Clonar:** `git clone <URL_DEL_REPO_UNIVERSAL> && cd ejemplos/machine-learning-pipeline`
3.  **Instalar Dependencias Python:**
    * *(Usando Poetry):* `poetry install`
    * *(Usando Hatch):* `hatch env create && hatch shell`
    * *(Usando pip):* `pip install -r requirements.txt` (si existe y estÃ¡ actualizado)
4.  **Obtener los Datos y Modelos Versionados:** DVC descargarÃ¡ los archivos necesarios desde el almacenamiento remoto configurado (o el cache local si ya existen).
    ```bash
    dvc pull
    ```
    *(Nota: Para el primer uso o si el remote no estÃ¡ configurado, podrÃ­as necesitar configurar un DVC remote: `dvc remote add ...`)*
5.  **Reproducir el Pipeline:** DVC ejecutarÃ¡ las etapas definidas en `dvc.yaml` cuyos inputs (datos, cÃ³digo, parÃ¡metros) hayan cambiado desde la Ãºltima ejecuciÃ³n.
    ```bash
    dvc repro
    ```
    DVC es inteligente: si solo cambiaste los parÃ¡metros de entrenamiento, solo re-ejecutarÃ¡ las etapas `train` y `evaluate` (si `train` es dependencia de `evaluate`), usando los datos procesados cacheados de ejecuciones anteriores.
6.  **Ejecutar una Etapa EspecÃ­fica:** Si solo quieres re-ejecutar la evaluaciÃ³n:
    ```bash
    dvc repro evaluate  # 'evaluate' es el nombre de la etapa en dvc.yaml
    ```
7.  **Explorar Cambios (Ejemplo):**
    * Modifica un parÃ¡metro en `params.yaml` (ej: `model.n_estimators`).
    * Ejecuta `dvc repro`. Observa cÃ³mo DVC detecta el cambio y re-ejecuta las etapas afectadas.
    * Compara mÃ©tricas con la versiÃ³n anterior: `dvc metrics diff HEAD~1`.
8.  **Ejecutar Pruebas:**
    ```bash
    pytest
    # O usando Poetry/Hatch: poetry run pytest / hatch run test
    ```

## Conceptos Clave (MLOps) Implementados ğŸ’¡

* **Reproducibilidad:** `dvc repro` + Git + DVC garantiza que cualquier persona con acceso pueda reproducir tus resultados y tu pipeline completo.
* **Versionado Integral:**
    * **CÃ³digo y ParÃ¡metros:** Versionados con Git (`src/`, `params.yaml`, `dvc.yaml`).
    * **Datos y Modelos:** Versionados con DVC (`data/`, `models/`). Git solo guarda los pequeÃ±os archivos `.dvc`.
    * **Pipeline:** La definiciÃ³n del pipeline (`dvc.yaml`) y el estado exacto de las dependencias/salidas (`dvc.lock`) estÃ¡n versionados en Git.
* **Modularidad:** El pipeline se divide en etapas lÃ³gicas (`dvc.yaml`) que mapean a scripts modulares en `src/`.
* **AutomatizaciÃ³n:** `dvc repro` automatiza la ejecuciÃ³n del pipeline.
* **ExperimentaciÃ³n:** Cambia `params.yaml` o cÃ³digo, ejecuta `dvc repro`, y usa `dvc metrics diff` / `dvc plots diff` para comparar experimentos fÃ¡cilmente. Puedes integrar MLflow en los scripts de `src/` para un seguimiento mÃ¡s detallado.

## Siguientes Pasos y AdaptaciÃ³n ğŸ‘£

* **Adapta los Scripts:** Modifica el cÃ³digo en `src/` para tu problema especÃ­fico y tus datos.
* **Cambia el Framework:** Reemplaza Scikit-learn por PyTorch, TensorFlow, etc. Adapta los scripts de entrenamiento/evaluaciÃ³n.
* **Configura DVC Remote:** Para colaboraciÃ³n o datos/modelos grandes, configura un almacenamiento remoto de DVC (S3, GCS, Azure Blob, SSH, etc.) usando `dvc remote add`.
* **Integra Experiment Tracking:** AÃ±ade logging a MLflow o W&B en tus scripts de `train` y `evaluate`.
* **AÃ±ade Etapas:** Define mÃ¡s etapas en `dvc.yaml` (ej: despliegue de modelo, generaciÃ³n de reportes).
* **CI/CD para ML:** Configura GitHub Actions o similar para ejecutar `dvc repro` o `pytest` en cada PR, o incluso re-entrenar y desplegar modelos automÃ¡ticamente. (Â¡Mira CML de Iterative AI!).

## Contribuciones a este Ejemplo âœ¨

Las mejoras a *esta plantilla especÃ­fica* son bienvenidas. Sigue la guÃ­a general (`comunidad/como-contribuir.md`) indicando que tu aporte es para `ejemplos/machine-learning-pipeline`.

Â¡Esperamos que esta estructura te ayude a construir pipelines de ML mÃ¡s robustos y reproducibles! ğŸ¤–ğŸ“ˆ

``` bash
ejemplos/machine-learning-pipeline/
â”œâ”€â”€ .dvc/                       # Directorio interno de DVC (config, cache local)
â”‚   â””â”€â”€ .gitignore              # Ignora el cache local en Git
â”‚   â””â”€â”€ config                  # ConfiguraciÃ³n local de DVC (remotes, etc.)
â”œâ”€â”€ .dvcignore                  # Archivos/patrones a ignorar por DVC (ej: logs, notebooks ejecutados)
â”œâ”€â”€ .gitignore                  # Archivos a ignorar por Git (entornos virtuales, __pycache__, .dvc/cache)
â”œâ”€â”€ .pre-commit-config.yaml     # (Opcional) Hooks para calidad de cÃ³digo/formato
â”œâ”€â”€ data/                       # Datos del proyecto (gestionados por DVC)
â”‚   â”œâ”€â”€ external/               # Datos de fuentes externas
â”‚   â”‚   â””â”€â”€ dataset.csv.dvc     # -> Archivo puntero de DVC al dato real
â”‚   â”œâ”€â”€ interim/                # Datos intermedios transformados
â”‚   â”‚   â””â”€â”€ features.pkl.dvc
â”‚   â”œâ”€â”€ processed/              # Datos finales listos para modelado
â”‚   â”‚   â”œâ”€â”€ test.csv.dvc
â”‚   â”‚   â””â”€â”€ train.csv.dvc
â”‚   â””â”€â”€ raw/                    # Datos originales inmutables
â”‚       â””â”€â”€ source_data.zip.dvc
â”œâ”€â”€ docs/                       # (Opcional) DocumentaciÃ³n del proyecto
â”‚   â””â”€â”€ index.md
â”œâ”€â”€ dvc.yaml                    # Â¡Define las etapas del pipeline DVC!
â”œâ”€â”€ environment.yml             # (Opcional) Para entornos Conda
â”œâ”€â”€ metrics.json                # (Generado por DVC) MÃ©tricas del modelo (versionado por Git/DVC)
â”œâ”€â”€ models/                     # Modelos entrenados (gestionados por DVC)
â”‚   â””â”€â”€ model.pkl.dvc           # -> Archivo puntero de DVC al modelo serializado
â”œâ”€â”€ notebooks/                  # Jupyter notebooks para exploraciÃ³n y prototipado
â”‚   â”œâ”€â”€ 1-data-exploration.ipynb
â”‚   â””â”€â”€ 2-model-prototyping.ipynb
â”œâ”€â”€ params.yaml                 # ParÃ¡metros y hiperparÃ¡metros (versionado por Git)
â”œâ”€â”€ plots.json                  # (Generado por DVC) MÃ©tricas/plots para comparar experimentos
â”œâ”€â”€ pyproject.toml              # Dependencias Python, build, metadata, config herramientas
â”œâ”€â”€ README.md                   # Este archivo: explicaciÃ³n del ejemplo
â”œâ”€â”€ references/                 # (Opcional) Diccionarios de datos, manuales, etc.
â”‚   â””â”€â”€ data_dictionary.md
â”œâ”€â”€ reports/                    # (Opcional, usualmente en .gitignore) Reportes generados, figuras
â”‚   â””â”€â”€ figures/
â”‚       â””â”€â”€ confusion_matrix.png
â”œâ”€â”€ requirements.txt            # (Alternativa a pyproject.toml o generado por Poetry/Hatch)
â”œâ”€â”€ src/                        # CÃ³digo fuente Python modularizado
â”‚   â””â”€â”€ ml_pipeline/            # Nombre del paquete principal
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data/               # MÃ³dulos para procesamiento de datos
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ make_dataset.py # Script para etapa DVC 'process_data'
â”‚       â”œâ”€â”€ features/           # MÃ³dulos para ingenierÃ­a de caracterÃ­sticas
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ build_features.py # Script para etapa DVC 'featurize'
â”‚       â”œâ”€â”€ models/             # MÃ³dulos para entrenamiento, evaluaciÃ³n, predicciÃ³n
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ evaluate_model.py # Script para etapa DVC 'evaluate'
â”‚       â”‚   â””â”€â”€ train_model.py    # Script para etapa DVC 'train'
â”‚       â”œâ”€â”€ utils.py            # Funciones de utilidad compartidas
â”‚       â””â”€â”€ visualization.py    # (Opcional) Scripts para generar visualizaciones
â””â”€â”€ tests/                      # Pruebas para el cÃ³digo en src/
    â”œâ”€â”€ conftest.py
    â”œâ”€â”€ data/                   # Datos pequeÃ±os para tests
    â”‚   â””â”€â”€ sample_raw.csv
    â”œâ”€â”€ test_data.py
    â””â”€â”€ test_features.py
```